{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e8765d0-2358-4af5-ba8f-edd49d08dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0109ce6a-cea5-4756-927b-54fc6e1353a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.228  Python-3.10.19 torch-2.9.1+cpu CPU (12th Gen Intel Core i5-12450H)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Rawda\\Yolo11\\Yolo11\\datasets\\neovision\\images, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\rawda\\runs\\classify\\train3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Rawda\\Yolo11\\Yolo11\\datasets\\neovision\\images\\train... found 356 images in 9 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Rawda\\Yolo11\\Yolo11\\datasets\\neovision\\images\\val... found 44 images in 9 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "Overriding model.yaml nc=1000 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    341769  ultralytics.nn.modules.head.Classify         [256, 9]                      \n",
      "YOLOv8n-cls summary: 56 layers, 1,449,817 parameters, 1,449,817 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.60.4 ms, read: 27.910.6 MB/s, size: 522.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Rawda\\Yolo11\\Yolo11\\datasets\\neovision\\images\\train... 356 images, 0 corrupt: 100% ━━━━━━━━━━━━ 356/356 505.9it/s 0.7s0.1s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Rawda\\Yolo11\\Yolo11\\datasets\\neovision\\images\\train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.60.7 ms, read: 38.023.2 MB/s, size: 624.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Rawda\\Yolo11\\Yolo11\\datasets\\neovision\\images\\val... 44 images, 0 corrupt: 100% ━━━━━━━━━━━━ 44/44 366.5it/s 0.1s0.1s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Rawda\\Yolo11\\Yolo11\\datasets\\neovision\\images\\val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000769, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\rawda\\runs\\classify\\train3\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\rawda\\AppData\\Roaming\\Ultralytics\\Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 625.1KB/s 1.2s.1s<0.1s4s\n",
      "\u001b[K       1/30         0G      2.182          4        224: 100% ━━━━━━━━━━━━ 12/12 2.8s/it 33.8s1.3s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.6s/it 2.6s\n",
      "                   all      0.182      0.727\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       2/30         0G      1.813          4        224: 100% ━━━━━━━━━━━━ 12/12 2.5s/it 30.5s1.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.7s/it 2.7s\n",
      "                   all      0.591      0.886\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       3/30         0G      1.347          4        224: 100% ━━━━━━━━━━━━ 12/12 2.7s/it 32.3s1.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.5s/it 2.5s\n",
      "                   all      0.636      0.932\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       4/30         0G     0.8813          4        224: 100% ━━━━━━━━━━━━ 12/12 2.7s/it 31.8s1.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.7s/it 2.7s\n",
      "                   all      0.773      0.977\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       5/30         0G     0.6685          4        224: 100% ━━━━━━━━━━━━ 12/12 2.6s/it 31.5s1.2s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.8s/it 2.8s\n",
      "                   all      0.841          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       6/30         0G     0.5219          4        224: 100% ━━━━━━━━━━━━ 12/12 2.7s/it 32.7s1.2s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.6s/it 2.6s\n",
      "                   all      0.864          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       7/30         0G      0.428          4        224: 100% ━━━━━━━━━━━━ 12/12 2.7s/it 31.9s1.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.4s/it 2.4s\n",
      "                   all      0.932          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       8/30         0G       0.44          4        224: 100% ━━━━━━━━━━━━ 12/12 2.6s/it 31.2s1.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.5s/it 2.5s\n",
      "                   all      0.886          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       9/30         0G      0.322          4        224: 100% ━━━━━━━━━━━━ 12/12 2.6s/it 31.7s1.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.5s/it 2.5s\n",
      "                   all      0.932          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      10/30         0G     0.3549          4        224: 100% ━━━━━━━━━━━━ 12/12 2.6s/it 31.6s1.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.7s/it 2.7s\n",
      "                   all      0.932          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      11/30         0G     0.2737          4        224: 100% ━━━━━━━━━━━━ 12/12 2.6s/it 30.7s1.2s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.6s/it 2.6s\n",
      "                   all      0.932          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      12/30         0G     0.3041          4        224: 100% ━━━━━━━━━━━━ 12/12 2.7s/it 32.1s1.3s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.7s/it 2.7s\n",
      "                   all      0.864          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      13/30         0G     0.3374          4        224: 100% ━━━━━━━━━━━━ 12/12 2.6s/it 31.4s1.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.5s/it 2.5s\n",
      "                   all      0.932          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      14/30         0G     0.2602          4        224: 100% ━━━━━━━━━━━━ 12/12 2.6s/it 31.1s1.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.7s/it 2.7s\n",
      "                   all      0.909          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      15/30         0G     0.3203          4        224: 100% ━━━━━━━━━━━━ 12/12 2.6s/it 31.5s1.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.5s/it 2.5s\n",
      "                   all      0.864          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      16/30         0G      0.277          4        224: 100% ━━━━━━━━━━━━ 12/12 2.7s/it 32.2s1.2s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.6s/it 2.6s\n",
      "                   all      0.841          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      17/30         0G      0.266          4        224: 100% ━━━━━━━━━━━━ 12/12 2.7s/it 31.8s1.3s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.6s/it 2.6s\n",
      "                   all      0.909          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      18/30         0G      0.229          4        224: 100% ━━━━━━━━━━━━ 12/12 2.6s/it 31.8s1.2s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.6s/it 2.6s\n",
      "                   all      0.909          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      19/30         0G     0.2592          4        224: 100% ━━━━━━━━━━━━ 12/12 2.6s/it 31.7s1.2s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.5s/it 2.5s\n",
      "                   all      0.886          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      20/30         0G     0.2565          4        224: 100% ━━━━━━━━━━━━ 12/12 2.7s/it 31.9s1.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.6s/it 2.6s\n",
      "                   all      0.886          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      21/30         0G     0.2362          4        224: 100% ━━━━━━━━━━━━ 12/12 2.7s/it 32.5s1.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.6s/it 2.6s\n",
      "                   all      0.886          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      22/30         0G     0.1865          4        224: 100% ━━━━━━━━━━━━ 12/12 2.6s/it 31.1s1.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.5s/it 2.5s\n",
      "                   all      0.909          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      23/30         0G     0.2144          4        224: 100% ━━━━━━━━━━━━ 12/12 2.6s/it 31.7s1.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.5s/it 2.5s\n",
      "                   all      0.909          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      24/30         0G     0.2713          4        224: 100% ━━━━━━━━━━━━ 12/12 2.7s/it 32.4s1.4s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.6s/it 2.6s\n",
      "                   all      0.886          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      25/30         0G     0.2153          4        224: 100% ━━━━━━━━━━━━ 12/12 2.6s/it 31.4s1.2s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.5s/it 2.5s\n",
      "                   all      0.932          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      26/30         0G     0.1621          4        224: 100% ━━━━━━━━━━━━ 12/12 2.7s/it 32.2s1.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.6s/it 2.6s\n",
      "                   all      0.932          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      27/30         0G     0.2109          4        224: 100% ━━━━━━━━━━━━ 12/12 2.6s/it 31.5s1.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.6s/it 2.6s\n",
      "                   all      0.864          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      28/30         0G     0.1655          4        224: 100% ━━━━━━━━━━━━ 12/12 2.7s/it 31.9s1.2s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.7s/it 2.7s\n",
      "                   all      0.886          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      29/30         0G     0.2041          4        224: 100% ━━━━━━━━━━━━ 12/12 2.6s/it 31.0s1.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.5s/it 2.5s\n",
      "                   all      0.886          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      30/30         0G     0.2432          4        224: 100% ━━━━━━━━━━━━ 12/12 2.6s/it 31.0s1.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.6s/it 2.6s\n",
      "                   all      0.886          1\n",
      "\n",
      "30 epochs completed in 0.288 hours.\n",
      "Optimizer stripped from C:\\Users\\rawda\\runs\\classify\\train3\\weights\\last.pt, 3.0MB\n",
      "Optimizer stripped from C:\\Users\\rawda\\runs\\classify\\train3\\weights\\best.pt, 3.0MB\n",
      "\n",
      "Validating C:\\Users\\rawda\\runs\\classify\\train3\\weights\\best.pt...\n",
      "Ultralytics 8.3.228  Python-3.10.19 torch-2.9.1+cpu CPU (12th Gen Intel Core i5-12450H)\n",
      "YOLOv8n-cls summary (fused): 30 layers, 1,446,409 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Rawda\\Yolo11\\Yolo11\\datasets\\neovision\\images\\train... found 356 images in 9 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Rawda\\Yolo11\\Yolo11\\datasets\\neovision\\images\\val... found 44 images in 9 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 2.3s/it 2.3s\n",
      "                   all      0.932          1\n",
      "Speed: 0.0ms preprocess, 9.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\rawda\\runs\\classify\\train3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001E192531000>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9659090936183929\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9318181872367859, 'metrics/accuracy_top5': 1.0, 'fitness': 0.9659090936183929}\n",
       "save_dir: WindowsPath('C:/Users/rawda/runs/classify/train3')\n",
       "speed: {'preprocess': 0.0014000000770796428, 'inference': 9.077613636360514, 'loss': 7.727265421470459e-05, 'postprocess': 0.0001386363444246606}\n",
       "task: 'classify'\n",
       "top1: 0.9318181872367859\n",
       "top5: 1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLO(\"yolov8n-cls.pt\")    \n",
    "model.train(\n",
    "    data=\"C:\\\\Rawda\\Yolo11\\\\Yolo11\\\\datasets\\\\neovision\\\\images\",    \n",
    "    epochs=30,         \n",
    "    imgsz=224,         \n",
    "    batch=32           \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee174351-e1df-4088-9a2b-b4b055c6a4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\rawda\\runs\\classify\\train3\\weights\\val.jpg: 224x224 White_iris 0.52, White_iris_dots 0.48, No_details 0.00, No_details_with_ring 0.00, Dark_iris 0.00, 185.9ms\n",
      "Speed: 227.8ms preprocess, 185.9ms inference, 3.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: None\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'Dark_iris', 1: 'Dark_iris_dots', 2: 'No_details', 3: 'No_details_dots', 4: 'No_details_with_ring', 5: 'No_details_with_ring_dots', 6: 'Nothing', 7: 'White_iris', 8: 'White_iris_dots'}\n",
      "obb: None\n",
      "orig_img: array([[[76, 47, 32],\n",
      "        [76, 47, 32],\n",
      "        [74, 48, 32],\n",
      "        ...,\n",
      "        [44, 38, 27],\n",
      "        [42, 38, 27],\n",
      "        [42, 38, 27]],\n",
      "\n",
      "       [[79, 50, 35],\n",
      "        [74, 48, 32],\n",
      "        [72, 46, 30],\n",
      "        ...,\n",
      "        [42, 36, 25],\n",
      "        [40, 36, 25],\n",
      "        [39, 35, 24]],\n",
      "\n",
      "       [[77, 51, 35],\n",
      "        [74, 49, 33],\n",
      "        [72, 47, 31],\n",
      "        ...,\n",
      "        [40, 33, 24],\n",
      "        [40, 33, 24],\n",
      "        [38, 31, 22]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[63, 43, 25],\n",
      "        [64, 44, 26],\n",
      "        [64, 44, 27],\n",
      "        ...,\n",
      "        [68, 45, 30],\n",
      "        [68, 45, 30],\n",
      "        [69, 46, 31]],\n",
      "\n",
      "       [[63, 46, 27],\n",
      "        [63, 46, 27],\n",
      "        [62, 44, 27],\n",
      "        ...,\n",
      "        [68, 46, 34],\n",
      "        [67, 45, 33],\n",
      "        [66, 44, 32]],\n",
      "\n",
      "       [[64, 47, 28],\n",
      "        [63, 46, 27],\n",
      "        [62, 43, 28],\n",
      "        ...,\n",
      "        [69, 47, 35],\n",
      "        [66, 44, 32],\n",
      "        [63, 41, 29]]], shape=(1228, 1624, 3), dtype=uint8)\n",
      "orig_shape: (1228, 1624)\n",
      "path: 'C:\\\\Users\\\\rawda\\\\runs\\\\classify\\\\train3\\\\weights\\\\val.jpg'\n",
      "probs: ultralytics.engine.results.Probs object\n",
      "save_dir: 'C:\\\\Users\\\\rawda\\\\runs\\\\classify\\\\predict'\n",
      "speed: {'preprocess': 227.84260000116774, 'inference': 185.8978999989631, 'postprocess': 3.3666999988781754}]\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"C:/Users/rawda/runs/classify/train3/weights/best.pt\")\n",
    "result = model(\"C:/Users/rawda/runs/classify/train3/weights/val.jpg\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71dc6118-82b1-4919-8ba2-0c5a1a07c898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\rawda\\runs\\classify\\train3\\weights\\NDWRD.jpg: 224x224 No_details_with_ring_dots 1.00, Dark_iris_dots 0.00, White_iris_dots 0.00, No_details_with_ring 0.00, No_details_dots 0.00, 27.6ms\n",
      "Speed: 19.3ms preprocess, 27.6ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: None\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'Dark_iris', 1: 'Dark_iris_dots', 2: 'No_details', 3: 'No_details_dots', 4: 'No_details_with_ring', 5: 'No_details_with_ring_dots', 6: 'Nothing', 7: 'White_iris', 8: 'White_iris_dots'}\n",
      "obb: None\n",
      "orig_img: array([[[44, 33, 25],\n",
      "        [44, 33, 25],\n",
      "        [44, 33, 25],\n",
      "        ...,\n",
      "        [45, 33, 27],\n",
      "        [46, 35, 27],\n",
      "        [45, 34, 26]],\n",
      "\n",
      "       [[44, 33, 25],\n",
      "        [44, 33, 25],\n",
      "        [44, 33, 25],\n",
      "        ...,\n",
      "        [45, 33, 27],\n",
      "        [44, 33, 25],\n",
      "        [44, 33, 25]],\n",
      "\n",
      "       [[44, 33, 25],\n",
      "        [44, 33, 25],\n",
      "        [44, 33, 25],\n",
      "        ...,\n",
      "        [43, 34, 25],\n",
      "        [42, 33, 24],\n",
      "        [41, 32, 23]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[45, 32, 24],\n",
      "        [45, 32, 24],\n",
      "        [46, 33, 25],\n",
      "        ...,\n",
      "        [45, 36, 27],\n",
      "        [45, 35, 28],\n",
      "        [45, 35, 28]],\n",
      "\n",
      "       [[46, 33, 25],\n",
      "        [45, 32, 24],\n",
      "        [46, 33, 25],\n",
      "        ...,\n",
      "        [47, 35, 29],\n",
      "        [46, 36, 29],\n",
      "        [46, 36, 29]],\n",
      "\n",
      "       [[47, 34, 26],\n",
      "        [46, 33, 25],\n",
      "        [46, 33, 25],\n",
      "        ...,\n",
      "        [46, 34, 28],\n",
      "        [46, 36, 29],\n",
      "        [46, 36, 29]]], shape=(1228, 1624, 3), dtype=uint8)\n",
      "orig_shape: (1228, 1624)\n",
      "path: 'C:\\\\Users\\\\rawda\\\\runs\\\\classify\\\\train3\\\\weights\\\\NDWRD.jpg'\n",
      "probs: ultralytics.engine.results.Probs object\n",
      "save_dir: 'C:\\\\Users\\\\rawda\\\\runs\\\\classify\\\\predict'\n",
      "speed: {'preprocess': 19.34819999951287, 'inference': 27.582999999140156, 'postprocess': 0.058000001445179805}]\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"C:/Users/rawda/runs/classify/train3/weights/best.pt\")\n",
    "result = model(\"C:/Users/rawda/runs/classify/train3/weights/NDWRD.jpg\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36dc6a3-8f11-4d0d-a80e-e89d981f17b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep Learning Env",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
